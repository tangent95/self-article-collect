{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class d2l(): # 请忽视，只是为了去除代码块中的错误信息提示，若运行请正确导入包\n",
    "    pass\n",
    "\n",
    "class AttentionDecoder(): # 此处仅仅是去除代码块中的错误信息提示，实际运行请在d2l中导入\n",
    "    pass\n",
    "\n",
    "def masked_softmax():\n",
    "    pass\n",
    "\n",
    "RUN=False # 代码没有数据处理，没法正常运行，需要修改代码\n",
    "if (not RUN):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0fd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "# 在书中，predict流程是通用的\n",
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    ### 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    \n",
    "    # 原句子预处理\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    ### 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    \n",
    "    # encoding\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    \n",
    "    \n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    ### 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        ### 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        ### 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        ### 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64bc6b",
   "metadata": {},
   "source": [
    "### 参数说明 / 次要的忽略\n",
    "|参数|type|描述|\n",
    "|-|-|-|\n",
    "|net|d2l.EncoderDecoder||\n",
    "|src_sentence|str|初始句子，新预测用于完善句子|\n",
    "|src_vocab|d2l.?|词表，用于将str句子转为数字索引 - tokenization|\n",
    "|tgt_vocab|d2l.?|target vocab|\n",
    "|num_steps|int?|具体含义/用途待定|\n",
    "\n",
    "### 运行\n",
    "1. 原句子预处理\n",
    "    \n",
    "    - str句子小写，按空格分离，转为token，追加&lt;pad&gt;token\n",
    "    - 填充&lt;pad&gt;或截断，确保src_tokens长度为设定的num_steps 形状：(num_steps,)\n",
    "    - 添加batch维度，形状(1, num_steps) **预测中的batch_size默认为1**\n",
    "\n",
    "\n",
    "2. encoding\n",
    "  \n",
    "    输出\n",
    "    - output (num_steps,batch_size,num_hiddens) 包含每个batch的GRU最后一层的在每个时间步的隐藏状态\n",
    "    - state (num_layers,batch_size,num_hiddens) 包含最后一时间步每个batch每层的隐藏状态\n",
    "\n",
    "    note:**隐藏状态可以理解为包含上下文信息(state)，也可以理解为包含预测的下一个词的概率(decoder在预测时传入上一个token，得到的output中包含下一词的信息，通过一个全连接层转化)**\n",
    "\n",
    "3. 预测\n",
    "    \n",
    "    - 初始化解码器状态(dec_state,会循环更新多次使用)\n",
    "    - 初始化编码器传入的词为&lt;bos&gt; (变量名dec_X)\n",
    "    - 进行num_steps次循环，直到生成的词为&lt;eos&gt;\n",
    "    - (循环)上一个词dec_X和解码器状态传入decoder，得到预测最高可能性的词元(1, 1, vocab_size)并更新解码器状态，用于下一次循环\n",
    "    - (循环)取得最大可能的词元，更新dec_X用于下一次预测；同时取得相应的token，加入最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768071a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "#@save\n",
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        output, state = self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19bdaf",
   "metadata": {},
   "source": [
    "### forward说明\n",
    "#### X形状\n",
    "|操作|形状|\n",
    "|-|-|\n",
    "|传参|(batch_size, num_steps)|\n",
    "|embedding|(batch_size, num_steps, embed_size)|\n",
    "|交换维度，适配rnn输入|(num_steps, batch_size, embed_size)|\n",
    "\n",
    "#### rnn输出参数说明 / 参考pytorch文档\n",
    "|符号|含义|\n",
    "|-|-|\n",
    "|N|batch_size|\n",
    "|L|序列长度 num_steps|\n",
    "|D|与双向GRU有关，双向为2，单向为1|\n",
    "|$H_in$|输入大小(GRU初始化时传入的是embed_size)|\n",
    "|$H_out$|隐藏层大小(GRU初始化时传入的是num_hiddens)|\n",
    "\n",
    "|文档参数|代码|描述|\n",
    "|-|-|-|\n",
    "|output|output|对于非批处理输入，其张量形状为 $(L,D∗H_out)$；当 'batch_first=False'(代码默认为'False') 时，形状为 $(L,N,D∗H_out)$；当 'batch_first=True'(可忽略) 时，形状为 $(N,L,D∗H_out)$，其中包含'GRU'最后一层在每个时间步't'的输出特征'(h_t)'。如果输入是'torch.nn.utils.rnn.PackedSequence'，则输出也将是打包序列。<br /><br />也就是说，代码中output形状为(num_steps, batch_size, num_hiddens)，包含每个batch的GRU最后一层的在每个时间步的隐藏状态(h_t)|\n",
    "|h_n|state|张量形状为$(D∗num_layers, H_out)$或$(D∗num_layers, N, H_out)$，包含输入序列的最终隐藏状态。<br /><br />也就是说，代码中state形状为(num_layers, batch_size, num_hiddens)，包含最后一时间步每个batch每层的隐藏状态|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder + attention\n",
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention = d2l.AdditiveAttention(\n",
    "            num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "            dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "        # hidden_state的形状为(num_layers,batch_size,\n",
    "        # num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # 输出X的形状为(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # context的形状为(batch_size,1,num_hiddens)\n",
    "            context = self.attention(\n",
    "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # 在特征维度上连结\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # 全连接层变换后，outputs的形状为\n",
    "        # (num_steps,batch_size,vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370222b",
   "metadata": {},
   "source": [
    "### init_state\n",
    "encoder的返回值传入其中，得到用于decoder.forward的state\n",
    "\n",
    "state:\n",
    "- enc_outputs (batch_size, num_steps, num_hiddens)\n",
    "- hidden_state (num_layers, batch_size, num_hiddens)\n",
    "- enc_valid_lens\n",
    "\n",
    "### forward\n",
    "#### 传参\n",
    "X：(batch_size, num_steps, embed_size) 预测中，batch_size=1 num_steps=1，训练中未知\n",
    "\n",
    "#### 流程(注意x的大小写)\n",
    "- 将X的时间步维度提前 (num_steps,batch_size,embed_size) (要逐个时间步处理数据)\n",
    "- (为什么要这样做可能与训练机制有关)逐个时间步提取出x(batch_size, embed_size) - X所有批次的指定时间步的词的embedding结果\n",
    "- (循环中)通过attention机制计算出上下文，与x拼接\n",
    "  + 使用最后一时间步最后一层的状态作为query(添加了维度，去适配attention的要求输入) query: (batch_size, 1, num_hiddens)\n",
    "  + 对GRU最后一层每个时间步的状态(同时作为key,value)进行查询 key/value: (batch_size, num_steps, num_hiddens) -> context: (batch_size, 1, num_hiddens)\n",
    "  + 为x增加维度，与context形状适配。context(前)与x拼接 -> x: (batch_size, 1, num_hiddens + embed_size)\n",
    "- (循环中)x交换维度，适配GRU，传入其中，得到out(1, batch_size, num_hiddens), hidden_state(num_layers, batch_size, num_hiddens)(可供下一轮使用)。out会累计到outputs(循环完成: (num_steps, batch_size, num_hiddens))里\n",
    "- 通过全连接层转化outputs，(看到形状里面的vocab_size你大概可以猜到是什么目的了) 得到(num_steps,batch_size,vocab_size)\n",
    "- 返回outputs(batch_size,num_steps,vocab_size)(交换了维度), dec_state(解码器状态)((batch_size, num_steps, num_hiddens), (num_layers, batch_size, num_hiddens), enc_valid_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention\n",
    "#@save\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcu126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
